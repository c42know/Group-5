{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target User\n",
    "target_users = (\"APTA_Transit\", \"BART\", \"MTA\", \"CTA\", \"MARTA\", \"RTCSNV\")\n",
    "\n",
    "# Tweet Texts\n",
    "tweet_texts = []\n",
    "tweet_date = []\n",
    "\n",
    "#variables for holding sentiments\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "counter_list = []\n",
    "target_list = []\n",
    "\n",
    "\n",
    "for target in target_users:\n",
    "    #Counter\n",
    "    counter = 1\n",
    "    # Create a loop to iteratively run API requests\n",
    "    for x in range(1, 6):\n",
    "\n",
    "        # Get all tweets from home feed (for each page specified)\n",
    "        public_tweets = api.user_timeline(target, page=x)\n",
    "\n",
    "        # Loop through all tweets\n",
    "        for tweet in public_tweets:\n",
    "\n",
    "            # Print Tweet\n",
    "            #print(tweet[\"text\"])\n",
    "\n",
    "            # Store Tweet in Array\n",
    "            tweet_texts.append(tweet[\"text\"])\n",
    "\n",
    "            # Store Tweet Date in Array\n",
    "            tweet_date.append(tweet[\"created_at\"])\n",
    "\n",
    "            # Run Vader Analysis on each tweet\n",
    "            results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "            compound = results[\"compound\"]\n",
    "            pos = results[\"pos\"]\n",
    "            neu = results[\"neu\"]\n",
    "            neg = results[\"neg\"]\n",
    "\n",
    "            # Add each value to the appropriate list\n",
    "            compound_list.append(compound)\n",
    "            positive_list.append(pos)\n",
    "            negative_list.append(neg)\n",
    "            neutral_list.append(neu)\n",
    "            counter_list.append(counter)\n",
    "            target_list.append(target)\n",
    "            # Store the data in dictionary\n",
    "            sentiment = {\n",
    "                \"User\": target_list,\n",
    "                \"Tweet\": tweet_texts,\n",
    "                \"Date\": tweet_date,\n",
    "                \"Compound\": compound_list,\n",
    "                \"Positive\": positive_list,\n",
    "                \"Neutral\": negative_list,\n",
    "                \"Negative\": neutral_list,\n",
    "                \"Tweets Ago\": counter_list\n",
    "            }\n",
    "            #add to counter\n",
    "            #print(target)\n",
    "            counter += 1\n",
    "\n",
    "#df = pd.DataFrame(sentiment)\n",
    "sentiment_df = pd.DataFrame(sentiment)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of      Compound                            Date  Negative  Neutral  Positive  \\\n",
       "0      0.8553  Wed Apr 11 21:22:08 +0000 2018     0.516    0.000     0.484   \n",
       "1      0.0000  Tue Apr 10 21:36:02 +0000 2018     1.000    0.000     0.000   \n",
       "2      0.7717  Tue Apr 10 13:23:30 +0000 2018     0.675    0.000     0.325   \n",
       "3      0.0000  Mon Apr 09 21:03:27 +0000 2018     1.000    0.000     0.000   \n",
       "4      0.0000  Fri Apr 06 21:21:35 +0000 2018     1.000    0.000     0.000   \n",
       "5      0.4588  Thu Apr 05 18:59:20 +0000 2018     0.870    0.000     0.130   \n",
       "6      0.7003  Wed Apr 04 20:59:16 +0000 2018     0.734    0.000     0.266   \n",
       "7      0.4199  Tue Apr 03 16:30:17 +0000 2018     0.823    0.000     0.177   \n",
       "8      0.0000  Mon Apr 02 21:26:03 +0000 2018     1.000    0.000     0.000   \n",
       "9      0.2732  Fri Mar 30 19:15:13 +0000 2018     0.884    0.000     0.116   \n",
       "10     0.3612  Thu Mar 29 21:44:52 +0000 2018     0.872    0.000     0.128   \n",
       "11     0.0000  Wed Mar 28 20:49:40 +0000 2018     1.000    0.000     0.000   \n",
       "12     0.8591  Tue Mar 27 21:39:46 +0000 2018     0.612    0.000     0.388   \n",
       "13     0.0772  Fri Mar 23 18:56:45 +0000 2018     0.741    0.122     0.138   \n",
       "14     0.0000  Thu Mar 22 15:15:10 +0000 2018     1.000    0.000     0.000   \n",
       "15    -0.1027  Wed Mar 21 15:15:11 +0000 2018     0.920    0.080     0.000   \n",
       "16     0.8020  Tue Mar 20 19:38:28 +0000 2018     0.725    0.000     0.275   \n",
       "17     0.0772  Tue Mar 20 14:28:56 +0000 2018     0.933    0.000     0.067   \n",
       "18     0.0000  Tue Mar 20 14:13:25 +0000 2018     1.000    0.000     0.000   \n",
       "19     0.2023  Tue Mar 20 14:07:02 +0000 2018     0.878    0.000     0.122   \n",
       "20     0.1521  Tue Mar 20 13:52:05 +0000 2018     0.885    0.000     0.115   \n",
       "21     0.6705  Tue Mar 20 13:49:42 +0000 2018     0.686    0.000     0.314   \n",
       "22     0.0000  Tue Mar 20 13:45:11 +0000 2018     1.000    0.000     0.000   \n",
       "23     0.4404  Tue Mar 20 13:20:49 +0000 2018     0.884    0.000     0.116   \n",
       "24     0.7964  Tue Mar 20 13:11:14 +0000 2018     0.728    0.000     0.272   \n",
       "25     0.4019  Tue Mar 20 13:08:29 +0000 2018     0.699    0.092     0.210   \n",
       "26    -0.1280  Tue Mar 20 13:00:47 +0000 2018     0.914    0.086     0.000   \n",
       "27    -0.7089  Tue Mar 20 12:55:58 +0000 2018     0.671    0.329     0.000   \n",
       "28     0.6115  Mon Mar 19 15:40:26 +0000 2018     0.750    0.000     0.250   \n",
       "29     0.0000  Mon Mar 19 15:24:49 +0000 2018     1.000    0.000     0.000   \n",
       "..        ...                             ...       ...      ...       ...   \n",
       "569   -0.5859  Tue Apr 10 14:28:47 +0000 2018     0.714    0.286     0.000   \n",
       "570   -0.5859  Tue Apr 10 14:19:36 +0000 2018     0.714    0.286     0.000   \n",
       "571   -0.2732  Tue Apr 10 11:40:35 +0000 2018     0.851    0.149     0.000   \n",
       "572    0.2263  Tue Apr 10 11:33:49 +0000 2018     0.733    0.110     0.157   \n",
       "573    0.0000  Tue Apr 10 11:11:06 +0000 2018     1.000    0.000     0.000   \n",
       "574    0.1280  Tue Apr 10 10:27:36 +0000 2018     0.754    0.111     0.136   \n",
       "575   -0.2732  Tue Apr 10 03:03:24 +0000 2018     0.870    0.130     0.000   \n",
       "576   -0.5859  Tue Apr 10 02:49:24 +0000 2018     0.758    0.242     0.000   \n",
       "577    0.0000  Tue Apr 10 02:07:24 +0000 2018     1.000    0.000     0.000   \n",
       "578   -0.5859  Tue Apr 10 01:15:37 +0000 2018     0.730    0.270     0.000   \n",
       "579   -0.5859  Tue Apr 10 00:52:54 +0000 2018     0.730    0.270     0.000   \n",
       "580    0.0000  Tue Apr 10 00:30:21 +0000 2018     1.000    0.000     0.000   \n",
       "581   -0.5859  Tue Apr 10 00:07:28 +0000 2018     0.730    0.270     0.000   \n",
       "582   -0.5859  Mon Apr 09 23:54:25 +0000 2018     0.730    0.270     0.000   \n",
       "583    0.0000  Mon Apr 09 23:05:07 +0000 2018     1.000    0.000     0.000   \n",
       "584   -0.5859  Mon Apr 09 22:58:25 +0000 2018     0.696    0.304     0.000   \n",
       "585    0.0000  Mon Apr 09 22:54:29 +0000 2018     1.000    0.000     0.000   \n",
       "586   -0.5859  Mon Apr 09 22:52:33 +0000 2018     0.714    0.286     0.000   \n",
       "587   -0.5859  Mon Apr 09 22:39:30 +0000 2018     0.730    0.270     0.000   \n",
       "588   -0.5859  Mon Apr 09 22:33:42 +0000 2018     0.714    0.286     0.000   \n",
       "589   -0.5859  Mon Apr 09 22:30:48 +0000 2018     0.745    0.255     0.000   \n",
       "590    0.0000  Mon Apr 09 21:40:15 +0000 2018     1.000    0.000     0.000   \n",
       "591   -0.5859  Mon Apr 09 20:05:47 +0000 2018     0.696    0.304     0.000   \n",
       "592   -0.5859  Mon Apr 09 19:01:30 +0000 2018     0.769    0.231     0.000   \n",
       "593   -0.5859  Mon Apr 09 18:05:26 +0000 2018     0.758    0.242     0.000   \n",
       "594    0.0000  Mon Apr 09 17:25:10 +0000 2018     1.000    0.000     0.000   \n",
       "595   -0.2023  Mon Apr 09 16:59:16 +0000 2018     0.714    0.175     0.111   \n",
       "596    0.1027  Mon Apr 09 16:53:54 +0000 2018     0.591    0.218     0.191   \n",
       "597   -0.5859  Mon Apr 09 16:32:38 +0000 2018     0.769    0.231     0.000   \n",
       "598   -0.2732  Mon Apr 09 16:00:44 +0000 2018     0.851    0.149     0.000   \n",
       "\n",
       "                                                 Tweet  Tweets Ago  \\\n",
       "0    Congratulations to @RideKCTransit on their new...           1   \n",
       "1    RT @APTA_info: “In late March, Congress approp...           2   \n",
       "2    Public transportation supports jobs in more wa...           3   \n",
       "3                              https://t.co/iNuedb2jYw           4   \n",
       "4                              https://t.co/zxMKT7Ulqs           5   \n",
       "5    We applaud Congress for standing up for public...           6   \n",
       "6    #Publictransportation has long operated in com...           7   \n",
       "7    #PublicTransit keeps America moving! Our publi...           8   \n",
       "8                              https://t.co/1OBAhsKXmk           9   \n",
       "9    DYK: Every $10 million in capital investment i...          10   \n",
       "10   RT @APTA_Transit: A majority of Mayors surveye...          11   \n",
       "11                             https://t.co/2hnpyifjwG          12   \n",
       "12   Congratulations to friend of transit @RepBonni...          13   \n",
       "13   We’re at a critical juncture for #publictransp...          14   \n",
       "14   Public transportation connects communities, be...          15   \n",
       "15   Using public transportation funding to pay for...          16   \n",
       "16   RT @repblumenauer: Glad to be a part of the @A...          17   \n",
       "17   \"If the federal government moves toward VMT th...          18   \n",
       "18   \"Who would invest all their money into one sto...          19   \n",
       "19   \"Transit and mass transit are important to my ...          20   \n",
       "20   \"People say they shouldn't pay for transit the...          21   \n",
       "21   \"We need you advocacy and your support to make...          22   \n",
       "22   \"93% of transit programs move quickly, the big...          23   \n",
       "23   \"I hope when you talk to your member of Congre...          24   \n",
       "24   \"We need a program to fund infrastructure prog...          25   \n",
       "25   \"The Adminstration tried to cut TIGER grants. ...          26   \n",
       "26   \"The Adminstration plan invests $200 billion i...          27   \n",
       "27   \"I've been especially frustrated with the cuts...          28   \n",
       "28   \"Capital Investment Grants would be used to ma...          29   \n",
       "29   ...in the nation. They reasonably expect the c...          30   \n",
       "..                                                 ...         ...   \n",
       "569  #FASTALERT 10-Apr-18 7:27 am,\\nCrash on I-215 ...          71   \n",
       "570  #FASTALERT 10-Apr-18 7:18 am,\\nCrash on I-215 ...          72   \n",
       "571  #FASTALERT 10-Apr-18 4:39 am,\\nCrash-incident ...          73   \n",
       "572  #FASTALERT 10-Apr-18 4:32 am,\\nCrash-incident ...          74   \n",
       "573  #FASTALERT 10-Apr-18 4:09 am,\\nUS-95 Northboun...          75   \n",
       "574  #FASTALERT 10-Apr-18 3:26 am,\\nTraffic-signal-...          76   \n",
       "575  #FASTALERT 09-Apr-18 7:48 pm,\\nCrash-incident ...          77   \n",
       "576  #FASTALERT 09-Apr-18 7:48 pm,\\nCrash on I-15 N...          78   \n",
       "577  #FASTALERT 09-Apr-18 7:00 pm,\\n=UPDATE= on Che...          79   \n",
       "578  #FASTALERT 09-Apr-18 6:14 pm,\\nCrash on CC-215...          80   \n",
       "579  #FASTALERT 09-Apr-18 5:51 pm,\\nCrash on I-215 ...          81   \n",
       "580  An outside lane along northbound U.S. 95 betwe...          82   \n",
       "581  #FASTALERT 09-Apr-18 5:06 pm,\\nCrash on US-95 ...          83   \n",
       "582  #FASTALERT 09-Apr-18 4:53 pm,\\nCrash on I-215 ...          84   \n",
       "583  .@NDOTProjectNeon ramp closures in place this ...          85   \n",
       "584  #FASTALERT 09-Apr-18 3:57 pm,\\nCrash on I-15 S...          86   \n",
       "585  #FASTALERT\\n4/9/2018  3:50 PM\\n\\nDue to Police...          87   \n",
       "586  #FASTALERT 09-Apr-18 3:51 pm,\\nCrash on US-95 ...          88   \n",
       "587  #FASTALERT 09-Apr-18 3:37 pm,\\nCrash on Cheyen...          89   \n",
       "588  #FASTALERT 09-Apr-18 3:31 pm,\\nCrash on I-215 ...          90   \n",
       "589  #FASTALERT 09-Apr-18 3:28 pm,\\nCrash on I-215 ...          91   \n",
       "590  It's National #WorkZoneAwarenessWeek! #RTCSNV ...          92   \n",
       "591  #FASTALERT 09-Apr-18 1:03 pm,\\nCrash on I-15 N...          93   \n",
       "592  #FASTALERT 09-Apr-18 12:00 pm,\\nCrash on Summe...          94   \n",
       "593  #FASTALERT 09-Apr-18 11:02 am,\\nCrash on Valle...          95   \n",
       "594  Traffic control flaggers will be present in Lo...          96   \n",
       "595  @MannyAyNV I apologize for this occurences and...          97   \n",
       "596  #FASTALERT 09-Apr-18 9:52 am,\\nCrash on Desert...          98   \n",
       "597  #FASTALERT 09-Apr-18 9:30 am,\\nCrash on Spring...          99   \n",
       "598  #FASTALERT 09-Apr-18 8:13 am,\\nScene-safety on...         100   \n",
       "\n",
       "             User  \n",
       "0    APTA_Transit  \n",
       "1    APTA_Transit  \n",
       "2    APTA_Transit  \n",
       "3    APTA_Transit  \n",
       "4    APTA_Transit  \n",
       "5    APTA_Transit  \n",
       "6    APTA_Transit  \n",
       "7    APTA_Transit  \n",
       "8    APTA_Transit  \n",
       "9    APTA_Transit  \n",
       "10   APTA_Transit  \n",
       "11   APTA_Transit  \n",
       "12   APTA_Transit  \n",
       "13   APTA_Transit  \n",
       "14   APTA_Transit  \n",
       "15   APTA_Transit  \n",
       "16   APTA_Transit  \n",
       "17   APTA_Transit  \n",
       "18   APTA_Transit  \n",
       "19   APTA_Transit  \n",
       "20   APTA_Transit  \n",
       "21   APTA_Transit  \n",
       "22   APTA_Transit  \n",
       "23   APTA_Transit  \n",
       "24   APTA_Transit  \n",
       "25   APTA_Transit  \n",
       "26   APTA_Transit  \n",
       "27   APTA_Transit  \n",
       "28   APTA_Transit  \n",
       "29   APTA_Transit  \n",
       "..            ...  \n",
       "569        RTCSNV  \n",
       "570        RTCSNV  \n",
       "571        RTCSNV  \n",
       "572        RTCSNV  \n",
       "573        RTCSNV  \n",
       "574        RTCSNV  \n",
       "575        RTCSNV  \n",
       "576        RTCSNV  \n",
       "577        RTCSNV  \n",
       "578        RTCSNV  \n",
       "579        RTCSNV  \n",
       "580        RTCSNV  \n",
       "581        RTCSNV  \n",
       "582        RTCSNV  \n",
       "583        RTCSNV  \n",
       "584        RTCSNV  \n",
       "585        RTCSNV  \n",
       "586        RTCSNV  \n",
       "587        RTCSNV  \n",
       "588        RTCSNV  \n",
       "589        RTCSNV  \n",
       "590        RTCSNV  \n",
       "591        RTCSNV  \n",
       "592        RTCSNV  \n",
       "593        RTCSNV  \n",
       "594        RTCSNV  \n",
       "595        RTCSNV  \n",
       "596        RTCSNV  \n",
       "597        RTCSNV  \n",
       "598        RTCSNV  \n",
       "\n",
       "[599 rows x 8 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Pandas create dataframes for each media company\n",
    "apta_sentiment_df = sentiment_df.loc[sentiment_df['User'] == 'APTA']\n",
    "bart_sentiment_df = sentiment_df.loc[sentiment_df['User'] == 'BART']\n",
    "mta_sentiment_df = sentiment_df.loc[sentiment_df['User'] == 'MTA']\n",
    "cta_sentiment_df = sentiment_df.loc[sentiment_df['User'] == 'CTA']\n",
    "marta_sentiment_df = sentiment_df.loc[sentiment_df['User'] == 'MARTA']\n",
    "rtcsnv_sentiment_df = sentiment_df.loc[sentiment_df['User'] == 'RTCSNV']\n",
    "\n",
    "#Average the compound vader analysis for each broadcasting company\n",
    "apta_compound_avg = (f\"{np.mean(apta_sentiment_df['Compound']):.3f}\")\n",
    "bart_compound_avg = (f\"{np.mean(bart_sentiment_df['Compound']):.3f}\")\n",
    "mta_compound_avg = (f\"{np.mean(mta_sentiment_df['Compound']):.3f}\")\n",
    "cta_compound_avg = (f\"{np.mean(cta_sentiment_df['Compound']):.3f}\")\n",
    "marta_compound_avg = (f\"{np.mean(marta_sentiment_df['Compound']):.3f}\")\n",
    "rtcsnv_compound_avg = (f\"{np.mean(rtcsnv_sentiment_df['Compound']):.3f}\")\n",
    "\n",
    "#create DF with all compounded averages\n",
    "compound_df = [apta_compound_avg, bart_compound_avg, mta_compound_avg, cta_compound_avg, marta_compound_avg, rtcsnv_compound_avg ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot  \n",
    "x_axis = np.arange(len(compund_df))\n",
    "\n",
    "plt.bar(x_axis, compound_df, color=('red', 'cyan', 'blue', 'yellow', 'green'), alpha=0.5, align=\"edge\")\n",
    "\n",
    "# Tell matplotlib where we would like to place each of our x axis headers\n",
    "tick_locations = [value+0.4 for value in x_axis]\n",
    "plt.xticks(tick_locations, target_users)\n",
    "\n",
    "# Give our chart some labels and a tile\n",
    "plt.title(\"Overall Media Sentiment Based on Twitter (4/10/17)\")\n",
    "plt.xlabel(\"Media Company\")\n",
    "plt.ylabel(\"Tweet Populalrity\")\n",
    "\n",
    "# Sets the y limits of the current chart\n",
    "#plt.ylim([-0.20,1])\n",
    "# Print our chart to the screen\n",
    "plt.show()\n",
    "plt.savefig(\"Avg_Media Sentiment_Bar_Plot_4-10-18.png\")\n",
    "#Sentiment values left to right\n",
    "#['0.118', '0.367', '0.002', '0.189', '0.015']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
